{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 파이토치 기본 자료구조인 텐서의 이해\n",
    "* 텐서를 인덱스로 접근해서 연산하기\n",
    "* 다차원 배열 넘파이와 연계해서 다루기\n",
    "* 성능 개선을 위해 GPU로 연산 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층신경망의 중간단계는 입력값의 특징을 잡아내는 부동소수점 수의 모음인 동시에 신경망에서 입력이 최종적으로 출력으로 표현되는 방법을 기술하기 위한 수단으로 데이터구조를 잡아낸다.\n",
    "\n",
    "중간 표현값은 부동소수좀으로 이루어져있고, 입력을 특징짓는 동시에 데이터구조를 잡아내어 신경망 출력과 어떻게 매핑되는지를 설명하는 데 중요한 역할을 한다.\n",
    "\n",
    "이러한 중간 표현값은 입력과 이전 층의 뉴련이 가진 가중치를 조합한 결과이다. \n",
    "\n",
    "* 텐서 : 임의의 차원을 가진 벡터나 행렬의 일반화된 개념 = 다차원 배열 = N차원 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 2., 1., 5.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성자에 파이썬 리스트를 넘겨도 된다\n",
    "points = torch.tensor([4.0, 1.0, 2.0, 1.0, 5.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([ [4.0, 1.0], [5.0, 3.0], [2.0, 1.0] ])\n",
    "print(points)\n",
    "print(points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이름이 있는 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1736, -0.4527,  0.0623, -0.2101, -2.1567],\n",
       "          [-0.8765,  0.1159, -1.8345,  0.0051, -2.7995],\n",
       "          [-1.1394,  1.5173,  1.1913,  0.5965, -1.3398],\n",
       "          [ 0.5310,  1.7657, -3.2736, -0.2540, -0.4868],\n",
       "          [ 1.2080,  0.9093,  1.1096, -0.1413, -0.2806]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5207, -1.7061,  0.2460,  0.0794, -0.1606],\n",
       "          [ 1.8150,  0.1819,  0.4458, -0.4629,  1.0726],\n",
       "          [-0.0621, -0.8098,  0.1403, -0.3068, -0.5323],\n",
       "          [ 0.7245,  0.1004, -0.8556, -0.2167, -0.0162],\n",
       "          [-1.5043, -0.7533,  0.0816, -0.6315, -0.2560]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # 채널크기, 행크기, 열크기\n",
    "weights = torch.tensor([0.2162, 0.7234, 0.3234])\n",
    "print(weights.size())\n",
    "batch_t = torch.randn(2, 1, 5, 5) # 배치크기, 채널크기, 행 크기, 열 크기\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채널이 3\n",
    "batch_t = torch.randn(2, 3, 5, 5)\n",
    "\n",
    "\n",
    "# RGB 채널은 0번 혹은 1번째 차원에 있다. 두 경우 모두 뒤에서 3번째 차원이므로 RGB 채널은 -3번 차원에 있는 것으로 일반화할 수 있다.\n",
    "\n",
    "# 배치 유무에 상관없이 평균을 구할 수 있다.\n",
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 브로드캐스팅 \n",
    "\n",
    "파이토치는 동일한 차원 정보의 텐서끼리 연산할 수 있고, 각 차원의 길이가 1인 텐서도 가능하다.\n",
    "\n",
    "혹은 길이가 1인 차원을 알아서 늘려주기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2, 3, 5, 5) 차원을 가진 batch_t 를 (3, 1 ,1) 차원의 unsqueezed_weights 로 곱하면 (2, 3, 5, 5) 차원이 된다.\n",
    "# 채널 정보를 가진, 뒤에서 세 번째 차원에 있는 값에 대한 합을 구할 수 있다.\n",
    "\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1) # (3) -> (3, 1) -> (3, 1, 1)\n",
    "\n",
    "\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "\n",
    "\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape\n",
    "\n",
    "# 서로 다른 차원을 가진 텐서는 원래 곱할 수 없는데, 파이토치가 편의상 동일한 차원으로 알아서 맞춰준 후 곱해주므로 (2, 3, 5, 5) 차원이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2142, 0.3234, 0.4321], names=('channels',))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor나 rand 같은 텐서 팩토리 함수에 이름으로 사용할 문자열 리스트를 names 인자로 전달할 수 있다.\n",
    "weights_named = torch.tensor([0.2142, 0.3234, 0.4321], names=['channels'])\n",
    "weights_named\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서끼리의 연산은 먼저 각 차원의 크기가 같은지, 한쪽이 1이고 다른쪽으로 브로드캐스팅 될 수 있는지 확인해야 한다. \n",
    "\n",
    "# 이름이 지정되어 있다면 파이토치가 우리를 대신해 알아서 체크해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'cols'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align 함수 : 빠진 채원을 채우고, 존재하는 차원을 올바른 순서로 바꿔준다.\n",
    "\n",
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'cols')\n",
    "\n",
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 요소 타입\n",
    "\n",
    "* 파이썬에서 숫자는 객체다. -> 백만 개가 넘어가면 비효율적이다.\n",
    "* 파이썬에서 리스트는 연속된 객체의 컬렉션이다. -> 두 벡터의 내적을 효율적으로 수행하는 연산이 없다.\n",
    "* 파이썬 인터프리터는 최적화를 거치는 컴파일된 코드보다 느리다. -> C같은 저수준 컴파일을 통해 최적화된 바이너리 코드가 훨씬 빠르다.\n",
    "\n",
    "-> 파이토치 텐서같이 전용 데이터 구조를 만든 후 숫자 데이터 연산은 저수준 언어로 효율을 높인다. 성능 최적화르 위해 텐서 내의 모든 객체는 같은 타입의 숫자여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype 으로 숫자 타입 지정하기 : 텐서의 기본 데이터 타입은 32비트 부동소수점(float32) 이다.\n",
    "# float 부동소수점\n",
    "# int 부호 있는 정수\n",
    "# uint 부호 없는 정수\n",
    "# bool 불리언\n",
    "\n",
    "\n",
    "\n",
    "# 변환이 필요한 경우 to 메소드 이용\n",
    "\n",
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "\n",
    "\n",
    "# 여러 타입을 가진 입력들이 연산을 거치며 서로 섞일 때, 자동으로 제일 큰 타입으로 만들어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서 API \n",
    "\n",
    "파이토치가 제공하는 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "\n",
    "a = torch.ones(3,2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 메소드 이용\n",
    "a = torch.ones(3, 2)\n",
    "a_t = a.transpose(0, 1)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서의 size = 넘파이의 shape\n",
    "# 오프셋 : 텐서의 첫번째 요소를 가리키는 색인 값\n",
    "# 스트라이드 : 각 차원에서 다음 요소를 가리키고 싶을 때 실제 저장 공간상에서 몇 개의 요소를 건너뛰어야 하는지 알려주는 숫자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [1., 3.],\n",
       "        [3., 9.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전치 transpose(), t()\n",
    "\n",
    "points = torch.tensor( [[4.0, 1.0], [1.0, 3.0], [3.0, 9.0]] )\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 3.],\n",
       "        [1., 3., 9.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/9jsw0prj36ngswky608_l6rc0000gn/T/ipykernel_57567/687426748.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  id(points.storage() == id(points_t.storage()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4334755728"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage() == id(points_t.storage())) # 두 텐서가 같은 공간을 가리키고 있는가? True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
